# Appendix A --- Frame Update Logic

We recorded our original ideation for how we implement frame updates, and why we publish all frame updates to a `/pose_updates` topic shared by all robots.
Some of this method introduced unnecessary complexity in implementing this project with only two robots and a target, but we outline it here as a sort of rationale for the overall approach --- the idea was to create a system that would be fairly consistent and not vulnerable to race conditions in events that would be more common with more robots looking at each other at the same time:



One significant design decision for the robot software was the implementation of the robot localization. Small changes in position are accounted for by encoders, but the drift in robot position is accounted for by each robot identifying each other robot (or identifying the target) visually via a marker, computing the relative pose difference between the two. 

We describe frame transforms using the TF2 library in ROS. TF2 builds a tree describing the relative transformations between different frames, and it’s worth noting that loops in the graph of frames are not permitted given that they would overconstrain the transforms — i.e. T_a->c and T_a->b * T_b->c describe the same transformation, so both cannot exist as separate transforms. This lends itself to a problem — Each robot can calculate its relative transform to another robot, yet in the TF2 tree, each is simply defined off of a transform to the world frame. Thus, when robot A sees robot B and needs to update their transform T_a->b, there are two free variables in the resulting equation: T_a->w and T_b->w (where w is the world frame every robot is based off of.) We have two problems here — determinism (how do we know which transform should be updated?) and race conditions (what if two robots see each other at the same time?)

Regarding determinism, the choice of which transform to update (or whether to update both of them some amount) ends up shifting the physical location of the world frame in space. If we try to hold our other robot->world transforms constant, the other robots will also end up shifting in physical space to align with the world frame. This shifting is inevitable — we really don’t know which transform is more “correct” and so we accept there’s some error in the other robots that will result in them shifting. (If we cared about some fixed world coordinate in space, we’d do some sort of pose graph optimization to minimize the error in our robot poses for every pose correction and produce some meaningful pose adjustment given this; in this case, we don’t care about the physical location of the origin, we just want the shifting of it to be deterministic/consistent.) However, if we enforce some order of “trust” of our different robots, we can at least ensure this shifting is deterministic. The easiest way to do this is number our robots and always update the transformation relating the higher-numbered robot to the world. This way, robot0 is always linked to the world frame simply by odometry, robot1 can be adjusted relative to robot0, robot2 adjusted relative to robot0 and robot1, etc.

The other issue is race conditions — both robots see each other at the same time, and if each tries to update their relative transform at the same time, we can get corrections applied twice. Enforcing an order of trust mitigates this to some extent — without error, each robot would try to apply the same transformation between the same frames — but we still get the messiness of both writing to the same transformation and taking priority over each other at random. To fix this, we need each transformation to have only one owner, and consider either having a single node own every transformation or having each robot update only its own. As we want our system to function in as distributed a manner as possible, we let each robot own its own transform relative to the world.

We then must define a way for a lower-numbered robot to let a higher-numbered robot know to update its transform. Either we have every robot broadcast every relative transform to a topic listened to by all robots, and have robots react when a message instructs them to update their own transform, or we give each robot a separate publisher for each other higher-numbered robot to directly instruct it to update its pose. From a performance perspective, the direct communication method wins out in terms of bandwidth for large swarms, with the number of messages sent scaling linearly with the number of robots. However, while the broadcast method scales quadratically with the number of robots, it is also much nicer and neater to implement (one topic, one publisher + one subscriber per robot), and given our small number of robots and very small message size (header, rotation, translation) we chose to implement this method for communicating frame transforms. 


